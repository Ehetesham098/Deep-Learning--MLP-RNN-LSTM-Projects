{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-121b698d521d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-121b698d521d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install hyperopt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "except:\n",
    "    !pip install hyperopt\n",
    "    from hyperopt import Trials, STATUS_OK, tpe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import psutil\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import logging\n",
    "import itertools as it\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print(\"checking if GPU available\", K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "print(\"current path\", os.getcwd())\n",
    "INPUT_PATH = os.path.join(PATH_TO_DRIVE_ML_DATA, \"inputs\")\n",
    "OUTPUT_PATH = os.path.join(PATH_TO_DRIVE_ML_DATA, \"outputs\")\n",
    "LOG_PATH = OUTPUT_PATH\n",
    "LOG_FILE_NAME_PREFIX = \"stock_pred_lstm_\"\n",
    "LOG_FILE_NAME_SUFFIX = \".log\"\n",
    "\n",
    "TIME_STEPS = 90  # 3 months\n",
    "BATCH_SIZE = 20\n",
    "stime = time.time()\n",
    "\n",
    "def print_time(text, stime):\n",
    "    seconds = (time.time() - stime)\n",
    "    print(text + \" \" + str(seconds // 60) + \" minutes : \" + str(np.round(seconds % 60)) + \" seconds\")\n",
    "\n",
    "def get_readable_ctime():\n",
    "    return time.strftime(\"%d-%m-%Y %H_%M_%S\")\n",
    "\n",
    "def init_logging():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    log_formatter = logging.Formatter(\"%(asctime)s [%(threadName)-12.12s] [%(levelname)-5.5s]  %(message)s\")\n",
    "    root_logger = logging.getLogger()\n",
    "\n",
    "    file_handler = logging.FileHandler(os.path.join(LOG_PATH, LOG_FILE_NAME_PREFIX + get_readable_ctime()+\".log\")) # \"{0}/{1}.log\".format(LOG_PATH, LOG_FILE_NAME_PREFIX + get_readable_ctime()))\n",
    "    file_handler.setFormatter(log_formatter)\n",
    "    root_logger.addHandler(file_handler)\n",
    "\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setFormatter(log_formatter)\n",
    "    root_logger.addHandler(console_handler)\n",
    "\n",
    "def trim_dataset(mat, batch_size):\n",
    "    \"\"\"\n",
    "    trims dataset to a size that's divisible by BATCH_SIZE\n",
    "    \"\"\"\n",
    "    no_of_rows_drop = mat.shape[0] % batch_size\n",
    "    if no_of_rows_drop > 0:\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat\n",
    "\n",
    "\n",
    "def build_timeseries(mat, y_col_index, time_steps):\n",
    "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "    dim_0 = mat.shape[0] - time_steps\n",
    "    dim_1 = mat.shape[1]\n",
    "    x = np.zeros((dim_0, time_steps, dim_1))\n",
    "    y = np.zeros((x.shape[0],))\n",
    "\n",
    "    for i in tqdm(range(dim_0)):\n",
    "        x[i] = mat[i:time_steps + i]\n",
    "        y[i] = mat[time_steps + i, y_col_index]\n",
    "    print(\"length of time-series i/o {} {}\".format(x.shape, y.shape))\n",
    "    return x, y\n",
    "\n",
    "stime = time.time()\n",
    "init_logging()\n",
    "print(str(os.listdir(INPUT_PATH)))  # ge.us.txt\n",
    "df_ge = pd.read_csv(os.path.join(INPUT_PATH,\"ge.us.txt\"), engine='python')\n",
    "print(str(df_ge.shape))\n",
    "print(str(df_ge.columns))\n",
    "\n",
    "train_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "df_train, df_test = train_test_split(df_ge, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "print(\"Train--Test size {} {}\".format(len(df_train), len(df_test)))\n",
    "\n",
    "# scale the feature MinMax, build array\n",
    "mat = df_ge.loc[:, train_cols].values\n",
    "\n",
    "print(\"Deleting unused dataframes of total size(KB) {}\"\n",
    "      .format((sys.getsizeof(df_ge) + sys.getsizeof(df_train) + sys.getsizeof(df_test)) // 1024))\n",
    "\n",
    "del df_ge\n",
    "del df_test\n",
    "del df_train\n",
    "\n",
    "csv_logger = CSVLogger(OUTPUT_PATH + 'log_' + get_readable_ctime() + '.log', append=True)\n",
    "\n",
    "class LogMetrics(Callback):\n",
    "\n",
    "    def __init__(self, search_params, param, comb_no):\n",
    "        self.param = param\n",
    "        self.self_params = search_params\n",
    "        self.comb_no = comb_no\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        for i, key in enumerate(self.self_params.keys()):\n",
    "            logs[key] = self.param[key]\n",
    "        logs[\"combination_number\"] = self.comb_no\n",
    "\n",
    "\n",
    "def data_dummy():\n",
    "    return None, None, None, None\n",
    "\n",
    "\n",
    "def data(batch_size, time_steps):\n",
    "    global mat\n",
    "\n",
    "    BATCH_SIZE = batch_size\n",
    "    TIME_STEPS = time_steps\n",
    "    x_train, x_test = train_test_split(mat, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # scale the train and test dataset\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    x_train = min_max_scaler.fit_transform(x_train)\n",
    "    x_test = min_max_scaler.transform(x_test)\n",
    "\n",
    "    x_train_ts, y_train_ts = build_timeseries(x_train, 3, TIME_STEPS)\n",
    "    x_test_ts, y_test_ts = build_timeseries(x_test, 3, TIME_STEPS)\n",
    "    x_train_ts = trim_dataset(x_train_ts, BATCH_SIZE)\n",
    "    y_train_ts = trim_dataset(y_train_ts, BATCH_SIZE)\n",
    "    x_test_ts = trim_dataset(x_test_ts, BATCH_SIZE)\n",
    "    y_test_ts = trim_dataset(y_test_ts, BATCH_SIZE)\n",
    "    print(\"Test size(trimmed) {}, {}\".format(x_test_ts.shape, y_test_ts.shape))\n",
    "\n",
    "    print(\"Are any NaNs present in train/test matrices?{0},{1}\".format(str(np.isnan(x_train).any()),\n",
    "                                                                       str(np.isnan(x_test).any())))\n",
    "    return x_train_ts, y_train_ts, x_test_ts, y_test_ts\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    'batch_size': hp.choice('bs', [30,40,50,60,70]),\n",
    "    'time_steps': hp.choice('ts', [30,50,60,80,90]),\n",
    "    'lstm1_nodes':hp.choice('units_lsmt1', [70,80,100,130]),\n",
    "    'lstm1_dropouts':hp.uniform('dos_lstm1',0,1),\n",
    "    'lstm_layers': hp.choice('num_layers_lstm',[\n",
    "        {\n",
    "            'layers':'one', \n",
    "        },\n",
    "        {\n",
    "            'layers':'two',\n",
    "            'lstm2_nodes':hp.choice('units_lstm2', [20,30,40,50]),\n",
    "            'lstm2_dropouts':hp.uniform('dos_lstm2',0,1)  \n",
    "        }\n",
    "        ]),\n",
    "    'dense_layers': hp.choice('num_layers_dense',[\n",
    "        {\n",
    "            'layers':'one'\n",
    "        },\n",
    "        {\n",
    "            'layers':'two',\n",
    "            'dense2_nodes':hp.choice('units_dense', [10,20,30,40])\n",
    "        }\n",
    "        ]),\n",
    "    \"lr\": hp.uniform('lr',0,1),\n",
    "    \"epochs\": hp.choice('epochs', [30, 40, 50, 60, 70]),\n",
    "    \"optimizer\": hp.choice('optmz',[\"sgd\", \"rms\"])\n",
    "}\n",
    "\n",
    "\n",
    "def create_model_hypopt(params):\n",
    "    print(\"Trying params:\",params)\n",
    "    batch_size = params[\"batch_size\"]\n",
    "    time_steps = params[\"time_steps\"]\n",
    "    x_train_ts, y_train_ts, x_test_ts, y_test_ts = data(batch_size, time_steps)\n",
    "    lstm_model = Sequential()\n",
    "    # (batch_size, timesteps, data_dim)\n",
    "    lstm_model.add(LSTM(params[\"lstm1_nodes\"], batch_input_shape=(batch_size, time_steps, x_train_ts.shape[2]), dropout=params[\"lstm1_dropouts\"],\n",
    "                        recurrent_dropout=params[\"lstm1_dropouts\"], stateful=True, return_sequences=True,\n",
    "                        kernel_initializer='random_uniform'))  \n",
    "    # ,return_sequences=True #LSTM params => dropout=0.2, recurrent_dropout=0.2\n",
    "    if params[\"lstm_layers\"][\"layers\"] == \"two\":\n",
    "        lstm_model.add(LSTM(params[\"lstm_layers\"][\"lstm2_nodes\"], dropout=params[\"lstm_layers\"][\"lstm2_dropouts\"]))\n",
    "    else:\n",
    "        lstm_model.add(Flatten())\n",
    "\n",
    "    if params[\"dense_layers\"][\"layers\"] == 'two':\n",
    "        lstm_model.add(Dense(params[\"dense_layers\"][\"dense2_nodes\"], activation='relu'))\n",
    "    \n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    lr = params[\"lr\"]\n",
    "    epochs = params[\"epochs\"]\n",
    "    if params[\"optimizer\"] == 'rms':\n",
    "        optimizer = optimizers.RMSprop(lr=lr)\n",
    "    else:\n",
    "        optimizer = optimizers.SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)  # binary_crossentropy\n",
    "    history = lstm_model.fit(x_train_ts, y_train_ts, epochs=epochs, verbose=2, batch_size=batch_size,\n",
    "                             validation_data=[x_test_ts, y_test_ts],\n",
    "                             callbacks=[LogMetrics(search_space, params, -1), csv_logger])\n",
    "    # for key in history.history.keys():\n",
    "    #     print(key, \"--\",history.history[key])\n",
    "    # get the highest validation accuracy of the training epochs\n",
    "    val_error = np.amin(history.history['val_loss']) \n",
    "    print('Best validation error of epoch:', val_error)\n",
    "    return {'loss': val_error, 'status': STATUS_OK, 'model': lstm_model} # if accuracy use '-' sign\n",
    "    \n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(create_model_hypopt,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=2000,\n",
    "    trials=trials)\n",
    "\n",
    "pickle.dump(best, open(os.path.join(OUTPUT_PATH,\"hyperopt_res\"),\"wb\"))\n",
    "\n",
    "print(best)\n",
    "print_time(\"program completed in\", stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x102f52d30>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/hyperopt/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x102f52630>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/hyperopt/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x102f52668>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/hyperopt/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x102f527b8>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/hyperopt/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x102f52390>, 'Connection to pypi.org timed out. (connect timeout=15)')': /simple/hyperopt/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement hyperopt (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for hyperopt\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-688774f97623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-688774f97623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install hyperopt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from hyperopt import Trials, STATUS_OK, tpe, fmin, hp\n",
    "except:\n",
    "    !pip install hyperopt\n",
    "    from hyperopt import Trials, STATUS_OK, tpe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "import keras\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# import psutil\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "import logging\n",
    "import itertools as it\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print(\"checking if GPU available\", K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "print(\"current path\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
